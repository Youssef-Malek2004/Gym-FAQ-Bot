version: "3.9"

services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    entrypoint: >
      sh -c "
        ollama serve &
        sleep 3 &&
        ollama pull gemma3:4b &&
        tail -f /dev/null
      "
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama


  backend:
    build: ./backend
    ports:
      - "8000:8000"
    depends_on:
      - ollama
    environment:
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
      - LANGCHAIN_TRACING_V2=true
      - LANGCHAIN_PROJECT=Gym Assistant
    volumes:
      - ./backend:/app

  frontend:
    build: ./frontend
    ports:
      - "8501:8501"
    depends_on:
      - backend
    environment:
      - STREAMLIT_SERVER_HEADLESS=true
    volumes:
      - ./frontend:/app

volumes:
  ollama-data:
